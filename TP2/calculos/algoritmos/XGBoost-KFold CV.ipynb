{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold CV XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 12\n",
    "TEST_SIZE_PERCENT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('test/training-person2.csv')\n",
    "test = pd.read_csv('test/test-person2.csv')\n",
    "sumbit = test['person'].to_frame()\n",
    "\n",
    "target_train = training['label'].values\n",
    "id_test = test['person'].values\n",
    "\n",
    "train = np.array(training.drop(['label'], axis = 1))\n",
    "test = np.array(test.drop(['person'], axis = 1))\n",
    "\n",
    "xgb_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = training['label']\n",
    "#X = training.drop(axis=1, labels=['label'])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE_PERCENT, random_state=RANDOM_SEED)\n",
    "\n",
    "#target_train = y_train.values\n",
    "#id_test = y_test.values\n",
    "\n",
    "#train =  np.array(X_train)\n",
    "#test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create K-fold cross-validation (K=4 here)\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 3228, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.828779\tvalid-auc:0.820564\ttrain-gini:0.678786\tvalid-gini:0.659834\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.875065\tvalid-auc:0.853479\ttrain-gini:0.75021\tvalid-gini:0.706909\n",
      "[100]\ttrain-auc:0.882441\tvalid-auc:0.85585\ttrain-gini:0.764959\tvalid-gini:0.71169\n",
      "[150]\ttrain-auc:0.889755\tvalid-auc:0.860211\ttrain-gini:0.779512\tvalid-gini:0.720401\n",
      "[200]\ttrain-auc:0.896598\tvalid-auc:0.860495\ttrain-gini:0.793196\tvalid-gini:0.72098\n",
      "[250]\ttrain-auc:0.905682\tvalid-auc:0.860956\ttrain-gini:0.811363\tvalid-gini:0.721912\n",
      "[300]\ttrain-auc:0.914537\tvalid-auc:0.861449\ttrain-gini:0.829075\tvalid-gini:0.722897\n",
      "[350]\ttrain-auc:0.921571\tvalid-auc:0.861484\ttrain-gini:0.843142\tvalid-gini:0.722967\n",
      "[400]\ttrain-auc:0.926989\tvalid-auc:0.861254\ttrain-gini:0.853977\tvalid-gini:0.722508\n",
      "[450]\ttrain-auc:0.93216\tvalid-auc:0.860679\ttrain-gini:0.864321\tvalid-gini:0.721357\n",
      "[500]\ttrain-auc:0.936865\tvalid-auc:0.860866\ttrain-gini:0.873729\tvalid-gini:0.721731\n",
      "[550]\ttrain-auc:0.941291\tvalid-auc:0.860424\ttrain-gini:0.882581\tvalid-gini:0.720847\n",
      "Stopping. Best iteration:\n",
      "[365]\ttrain-auc:0.9231\tvalid-auc:0.861796\ttrain-gini:0.846201\tvalid-gini:0.723591\n",
      "\n",
      "[0]\ttrain-auc:0.828163\tvalid-auc:0.841559\ttrain-gini:0.678721\tvalid-gini:0.6952\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.873009\tvalid-auc:0.866522\ttrain-gini:0.746057\tvalid-gini:0.732975\n",
      "[100]\ttrain-auc:0.880204\tvalid-auc:0.868028\ttrain-gini:0.760336\tvalid-gini:0.735777\n",
      "[150]\ttrain-auc:0.887349\tvalid-auc:0.868303\ttrain-gini:0.774692\tvalid-gini:0.736497\n",
      "[200]\ttrain-auc:0.894695\tvalid-auc:0.869925\ttrain-gini:0.789389\tvalid-gini:0.739847\n",
      "[250]\ttrain-auc:0.904637\tvalid-auc:0.872573\ttrain-gini:0.809274\tvalid-gini:0.745145\n",
      "[300]\ttrain-auc:0.912417\tvalid-auc:0.873061\ttrain-gini:0.824835\tvalid-gini:0.746122\n",
      "[350]\ttrain-auc:0.91865\tvalid-auc:0.873088\ttrain-gini:0.837301\tvalid-gini:0.746177\n",
      "[400]\ttrain-auc:0.924426\tvalid-auc:0.872281\ttrain-gini:0.848852\tvalid-gini:0.744562\n",
      "[450]\ttrain-auc:0.92967\tvalid-auc:0.872518\ttrain-gini:0.85934\tvalid-gini:0.745036\n",
      "Stopping. Best iteration:\n",
      "[287]\ttrain-auc:0.910531\tvalid-auc:0.873289\ttrain-gini:0.821062\tvalid-gini:0.746578\n",
      "\n",
      "[0]\ttrain-auc:0.82539\tvalid-auc:0.808193\ttrain-gini:0.671004\tvalid-gini:0.637454\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.874942\tvalid-auc:0.851772\ttrain-gini:0.749596\tvalid-gini:0.70374\n",
      "[100]\ttrain-auc:0.883016\tvalid-auc:0.851954\ttrain-gini:0.765877\tvalid-gini:0.704112\n",
      "[150]\ttrain-auc:0.890423\tvalid-auc:0.853922\ttrain-gini:0.780844\tvalid-gini:0.707813\n",
      "[200]\ttrain-auc:0.898194\tvalid-auc:0.854815\ttrain-gini:0.796388\tvalid-gini:0.709623\n",
      "[250]\ttrain-auc:0.908221\tvalid-auc:0.855317\ttrain-gini:0.816442\tvalid-gini:0.710635\n",
      "[300]\ttrain-auc:0.91703\tvalid-auc:0.854857\ttrain-gini:0.834059\tvalid-gini:0.709713\n",
      "[350]\ttrain-auc:0.92348\tvalid-auc:0.85414\ttrain-gini:0.846961\tvalid-gini:0.70828\n",
      "[400]\ttrain-auc:0.929388\tvalid-auc:0.853509\ttrain-gini:0.858776\tvalid-gini:0.707018\n",
      "[450]\ttrain-auc:0.934475\tvalid-auc:0.852458\ttrain-gini:0.86895\tvalid-gini:0.704917\n",
      "Stopping. Best iteration:\n",
      "[261]\ttrain-auc:0.910435\tvalid-auc:0.855512\ttrain-gini:0.820869\tvalid-gini:0.711024\n",
      "\n",
      "[0]\ttrain-auc:0.83603\tvalid-auc:0.822948\ttrain-gini:0.688683\tvalid-gini:0.660231\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.875896\tvalid-auc:0.847751\ttrain-gini:0.751649\tvalid-gini:0.696565\n",
      "[100]\ttrain-auc:0.882712\tvalid-auc:0.852956\ttrain-gini:0.765266\tvalid-gini:0.706018\n",
      "[150]\ttrain-auc:0.890233\tvalid-auc:0.855901\ttrain-gini:0.780424\tvalid-gini:0.711828\n",
      "[200]\ttrain-auc:0.898078\tvalid-auc:0.855921\ttrain-gini:0.796143\tvalid-gini:0.711847\n",
      "[250]\ttrain-auc:0.907558\tvalid-auc:0.856556\ttrain-gini:0.815116\tvalid-gini:0.713113\n",
      "[300]\ttrain-auc:0.915743\tvalid-auc:0.856955\ttrain-gini:0.831485\tvalid-gini:0.713908\n",
      "[350]\ttrain-auc:0.92207\tvalid-auc:0.856959\ttrain-gini:0.84414\tvalid-gini:0.713916\n",
      "[400]\ttrain-auc:0.928217\tvalid-auc:0.856916\ttrain-gini:0.856434\tvalid-gini:0.713833\n",
      "[450]\ttrain-auc:0.933718\tvalid-auc:0.856531\ttrain-gini:0.867435\tvalid-gini:0.713062\n",
      "[500]\ttrain-auc:0.938651\tvalid-auc:0.855935\ttrain-gini:0.877302\tvalid-gini:0.711869\n",
      "Stopping. Best iteration:\n",
      "[321]\ttrain-auc:0.91869\tvalid-auc:0.857396\ttrain-gini:0.837379\tvalid-gini:0.714792\n",
      "\n",
      "[0]\ttrain-auc:0.820175\tvalid-auc:0.769627\ttrain-gini:0.670104\tvalid-gini:0.577811\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.876478\tvalid-auc:0.830401\ttrain-gini:0.75282\tvalid-gini:0.664292\n",
      "[100]\ttrain-auc:0.884516\tvalid-auc:0.835987\ttrain-gini:0.768835\tvalid-gini:0.673342\n",
      "[150]\ttrain-auc:0.89129\tvalid-auc:0.840634\ttrain-gini:0.782474\tvalid-gini:0.681992\n",
      "[200]\ttrain-auc:0.899785\tvalid-auc:0.844872\ttrain-gini:0.79957\tvalid-gini:0.68975\n",
      "[250]\ttrain-auc:0.909183\tvalid-auc:0.847862\ttrain-gini:0.818366\tvalid-gini:0.695725\n",
      "[300]\ttrain-auc:0.917794\tvalid-auc:0.849254\ttrain-gini:0.835587\tvalid-gini:0.698508\n",
      "[350]\ttrain-auc:0.924209\tvalid-auc:0.849308\ttrain-gini:0.848418\tvalid-gini:0.698617\n",
      "[400]\ttrain-auc:0.929929\tvalid-auc:0.848929\ttrain-gini:0.859859\tvalid-gini:0.697858\n",
      "[450]\ttrain-auc:0.934391\tvalid-auc:0.848039\ttrain-gini:0.868783\tvalid-gini:0.696078\n",
      "[500]\ttrain-auc:0.93926\tvalid-auc:0.847686\ttrain-gini:0.87852\tvalid-gini:0.695372\n",
      "Stopping. Best iteration:\n",
      "[323]\ttrain-auc:0.920866\tvalid-auc:0.849432\ttrain-gini:0.841733\tvalid-gini:0.698864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(train):\n",
    "    train_X, valid_X = train[train_index], train[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, feval=gini_xgb, maximize=True, verbose_eval=50, early_stopping_rounds=200)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    xgb_preds.append(list(xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "output = pd.DataFrame({'person': id_test, 'label': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3883, 19415]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-40875cfd1f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[0;32m--> 272\u001b[0;31m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3883, 19415]"
     ]
    }
   ],
   "source": [
    "#roc_auc_score(y_test, output['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('test/sumbit-XGB-CV.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
